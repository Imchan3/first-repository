{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa84a7c9",
   "metadata": {},
   "source": [
    "# EX_2\n",
    "\n",
    "손글씨, 와인 분류, 유방암 진단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43776610",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 불러오기\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "#학습 및 결과에 필요한 패키지 불러오기\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "#적용할 모델 불러오기\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a653f6",
   "metadata": {},
   "source": [
    "데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "641dd4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#손글씨\n",
    "digits = load_digits()\n",
    "digits_data = digits.data\n",
    "digits_label = digits.target\n",
    "\n",
    "#와인\n",
    "wine = load_wine()\n",
    "wine_data = wine.data\n",
    "wine_label = wine.target\n",
    "\n",
    "#유방암\n",
    "breast_cancer = load_breast_cancer()\n",
    "breast_cancer_data = b_cancer.data\n",
    "breast_cancer_label = b_cancer.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baefe18e",
   "metadata": {},
   "source": [
    "## 1. 손글씨 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65f7dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trian, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data,  \n",
    "                                                    digits_label,  \n",
    "                                                    test_size=0.2,   \n",
    "                                                    random_state=7)\n",
    "                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87f8ed67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.81      0.81      0.81        42\n",
      "           2       0.79      0.82      0.80        40\n",
      "           3       0.79      0.91      0.85        34\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       0.84      0.93      0.88        28\n",
      "           7       0.96      0.82      0.89        33\n",
      "           8       0.88      0.65      0.75        43\n",
      "           9       0.78      0.78      0.78        32\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.85       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "732a575f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.93      1.00      0.97        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       0.93      1.00      0.96        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       1.00      0.84      0.91        43\n",
      "           9       0.94      0.94      0.94        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.97      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32) \n",
    "random_forest.fit(X_train, y_train) \n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f46e451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "217e67b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.83      0.95      0.89        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      0.82      0.90        34\n",
      "           4       0.88      1.00      0.94        37\n",
      "           5       0.78      1.00      0.88        28\n",
      "           6       1.00      0.93      0.96        28\n",
      "           7       0.97      0.91      0.94        33\n",
      "           8       0.88      0.86      0.87        43\n",
      "           9       0.96      0.75      0.84        32\n",
      "\n",
      "    accuracy                           0.92       360\n",
      "   macro avg       0.93      0.92      0.92       360\n",
      "weighted avg       0.93      0.92      0.92       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SGD Classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "acdeee30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      0.95      0.95        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.97      0.96        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.79      0.96      0.87        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       0.92      0.81      0.86        43\n",
      "           9       0.97      0.88      0.92        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=3000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6519ba3e",
   "metadata": {},
   "source": [
    "## 손글씨 분류 모델평가\n",
    "\n",
    "모델 | 정확도 | precision | recall   \n",
    ":---: | :---: | :---: | :---:  \n",
    "Decision Tree       | 0.86 | 0.86 | 0.86\n",
    "Random Forest     | 0.96  | 0.96 | 0.96\n",
    "SVM               | 0.99  | 0.99 | 0.99\n",
    "SGD Classifier    | 0.93  | 0.93 | 0.93\n",
    " Logistic Regression | 0.95| 0.95 | 0.95\n",
    "\n",
    "---\n",
    "\n",
    "모델별 정확도와 precision, recall 평균값을 비교해 봤을 때,\n",
    "SVM모델이 모든 지표에서 가장 높게 나왔으므로 가장 적절한 선택이 되겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12ca252",
   "metadata": {},
   "source": [
    "## 2. 와인 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ce55c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trian, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_data,  \n",
    "                                                    wine_label,  \n",
    "                                                    test_size=0.2,   \n",
    "                                                    random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d8e3d8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      1.00      0.94        17\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c51a560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32) \n",
    "random_forest.fit(X_train, y_train) \n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0147c7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86         7\n",
      "           1       0.58      0.88      0.70        17\n",
      "           2       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.59      0.61      0.56        36\n",
      "weighted avg       0.55      0.61      0.54        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8861f245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.88      0.41      0.56        17\n",
      "           2       0.55      0.92      0.69        12\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.77      0.78      0.73        36\n",
      "weighted avg       0.77      0.69      0.68        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SGD Classifier\n",
    "\n",
    "sgd_model = SGDClassifier(max_iter=3000)\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b3d145a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=4000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68627c95",
   "metadata": {},
   "source": [
    "## 와인 분류 모델평가\n",
    "\n",
    "\n",
    "모델 | 정확도 | precision | recall   \n",
    ":---: | :---: | :---: | :---:  \n",
    "Decision Tree       | 0.96 | 0.94 | 0.94\n",
    "Random Forest     | 1.00  | 1.00 | 1.00\n",
    "SVM               | 0.59  | 0.61| 0.56\n",
    "SGD Classifier    | 0.77  | 0.78 | 0.73\n",
    " Logistic Regression | 0.98| 0.97 | 0.97\n",
    "\n",
    "---\n",
    "\n",
    "모델별 정확도와 precision, recall 비교해봤을 때 Random Forest가 모든 부분이 1.00으로\n",
    "가장 높게 나왔으므로 가장 적절한 선택이 되겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5d9246",
   "metadata": {},
   "source": [
    "## 3. 유방암 진단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6181e3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trian, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(breast_cancer_data,\n",
    "                                                    breast_cancer_label,\n",
    "                                                    test_size=0.2,   \n",
    "                                                    random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "30e3a871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87        40\n",
      "           1       0.91      0.96      0.93        74\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.89      0.90       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6bc944b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       1.00      1.00      1.00        74\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32) \n",
    "random_forest.fit(X_train, y_train) \n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5c5db78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        40\n",
      "           1       0.87      1.00      0.93        74\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.94      0.86      0.89       114\n",
      "weighted avg       0.92      0.90      0.90       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "01f7f3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.83        40\n",
      "           1       0.93      0.88      0.90        74\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.86      0.88      0.87       114\n",
      "weighted avg       0.88      0.88      0.88       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SGD Classifier\n",
    "\n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "80f2386e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        40\n",
      "           1       0.93      1.00      0.96        74\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.96      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=3000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd12926",
   "metadata": {},
   "source": [
    "## 유방암 진단 모델평가\n",
    "\n",
    "모델 | 정확도 | precision | recall   \n",
    ":---: | :---: | :---: | :---:  \n",
    "Decision Tree       | 0.91 | 0.89 | 0.91\n",
    "Random Forest     | 1.00  | 1.00 | 1.00\n",
    "SVM               | 0.94  | 0.86| 0.90\n",
    "SGD Classifier    | 0.86  | 0.88 | 0.88\n",
    " Logistic Regression | 0.96| 0.93 | 0.95\n",
    " \n",
    " ---\n",
    " 모델별 정확도와 precision, recall 비교해봤을 때 Random Forest가 모든 부분이 1.00으로\n",
    "가장 높게 나왔으므로 가장 적절한 선택이 되겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685b1a32",
   "metadata": {},
   "source": [
    "## Exproation_2 회고\n",
    "\n",
    "첫번쨰 익스였던 가위바위보 를 할때보다는 수월하게 했다. 가위바위보를 할 때는 모든 것을 다 이해하려고 해서 더 어렵게 느꼈던 거 같았다. 모르는 코드들이 너무나 많았기에 그것들에 대해서 찾아보고 이해하는데 시간이 너무 오래 걸렸다. 결국 다 이해하지도 못했다.\n",
    "그래서 이번에는 그냥 흐름만 파악하려고 하였더니 수월하게 진행이 되었다. 코드에 대해서는 이론적으로 이해는 다 못했지만 이러한 동작을 하는구나 정도로 생각하고 넘어갔다. 이런 방식으로 하는게 맞는건지 가위바위보를 했던 거처럼 하는게 맞는건지 모르겠지만 익스를 진행하는 방식은 이번에 했던 방식이 나에게는 맞는거 같다. 코드의 용도만 알고 이론적인 부분은 나중에 이해해보는게 더 나을거 같다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
